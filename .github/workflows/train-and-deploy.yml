name: MLOps Training and Deployment Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      deploy_to_production:
        description: 'Deploy to production'
        required: false
        default: 'false'

jobs:
  train:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Check Databricks credentials
      id: check_databricks
      run: |
        # Check if required Databricks secrets are available
        if [ -n "${{ secrets.DATABRICKS_HOST }}" ] && [ -n "${{ secrets.DATABRICKS_TOKEN }}" ]; then
          echo "databricks_available=true" >> $GITHUB_OUTPUT
          echo "✓ Databricks credentials found in GitHub Secrets"
          echo "  Host: ${{ secrets.DATABRICKS_HOST }}"
          # Check for optional secrets
          if [ -n "${{ secrets.DATABRICKS_WORKSPACE_PATH }}" ]; then
            echo "  Workspace Path: ${{ secrets.DATABRICKS_WORKSPACE_PATH }}"
          fi
          if [ -n "${{ secrets.DATABRICKS_EXPERIMENT_PATH }}" ]; then
            echo "  Experiment Path: ${{ secrets.DATABRICKS_EXPERIMENT_PATH }}"
          fi
        else
          echo "databricks_available=false" >> $GITHUB_OUTPUT
          echo "⚠ Databricks credentials not found in GitHub Secrets"
          echo "  → Using local mode (SQLite) for MLflow tracking"
          echo "  → To enable Databricks, add DATABRICKS_HOST and DATABRICKS_TOKEN secrets"
        fi
    
    - name: Set up environment for Databricks
      if: steps.check_databricks.outputs.databricks_available == 'true'
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        DATABRICKS_WORKSPACE_PATH: ${{ secrets.DATABRICKS_WORKSPACE_PATH }}
        DATABRICKS_EXPERIMENT_PATH: ${{ secrets.DATABRICKS_EXPERIMENT_PATH }}
        MLFLOW_TRACKING_URI: databricks
      run: |
        echo "DATABRICKS_HOST=$DATABRICKS_HOST" >> $GITHUB_ENV
        echo "DATABRICKS_TOKEN=$DATABRICKS_TOKEN" >> $GITHUB_ENV
        echo "DATABRICKS_WORKSPACE_PATH=$DATABRICKS_WORKSPACE_PATH" >> $GITHUB_ENV
        echo "DATABRICKS_EXPERIMENT_PATH=$DATABRICKS_EXPERIMENT_PATH" >> $GITHUB_ENV
        echo "MLFLOW_TRACKING_URI=$MLFLOW_TRACKING_URI" >> $GITHUB_ENV
        echo "✓ Environment configured for Databricks"
        echo "✓ Databricks credentials loaded from GitHub Secrets"
    
    - name: Set up environment for local mode
      if: steps.check_databricks.outputs.databricks_available == 'false'
      run: |
        echo "MLFLOW_TRACKING_URI=sqlite:///mlflow.db" >> $GITHUB_ENV
        echo "✓ Environment configured for local mode (SQLite)"
    
    - name: Run tests
      run: |
        pytest tests/ || echo "No tests found, skipping..."
    
    - name: Train model
      run: |
        python src/train_model.py
    
    - name: Deploy to Staging
      if: github.ref == 'refs/heads/main'
      run: |
        python src/deploy_model.py --stage staging
  
  deploy-production:
    needs: train
    runs-on: ubuntu-latest
    if: github.event.inputs.deploy_to_production == 'true' || (github.ref == 'refs/heads/main' && contains(github.event.head_commit.message, '[deploy-prod]'))
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Check Databricks credentials
      id: check_databricks
      run: |
        if [ -n "${{ secrets.DATABRICKS_HOST }}" ] && [ -n "${{ secrets.DATABRICKS_TOKEN }}" ]; then
          echo "databricks_available=true" >> $GITHUB_OUTPUT
          echo "✓ Databricks credentials found in GitHub Secrets"
        else
          echo "databricks_available=false" >> $GITHUB_OUTPUT
          echo "⚠ Databricks credentials not found, using local mode"
        fi
    
    - name: Set up environment for Databricks
      if: steps.check_databricks.outputs.databricks_available == 'true'
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        DATABRICKS_WORKSPACE_PATH: ${{ secrets.DATABRICKS_WORKSPACE_PATH }}
        DATABRICKS_EXPERIMENT_PATH: ${{ secrets.DATABRICKS_EXPERIMENT_PATH }}
        MLFLOW_TRACKING_URI: databricks
      run: |
        echo "DATABRICKS_HOST=$DATABRICKS_HOST" >> $GITHUB_ENV
        echo "DATABRICKS_TOKEN=$DATABRICKS_TOKEN" >> $GITHUB_ENV
        [ -n "$DATABRICKS_WORKSPACE_PATH" ] && echo "DATABRICKS_WORKSPACE_PATH=$DATABRICKS_WORKSPACE_PATH" >> $GITHUB_ENV || true
        [ -n "$DATABRICKS_EXPERIMENT_PATH" ] && echo "DATABRICKS_EXPERIMENT_PATH=$DATABRICKS_EXPERIMENT_PATH" >> $GITHUB_ENV || true
        echo "MLFLOW_TRACKING_URI=$MLFLOW_TRACKING_URI" >> $GITHUB_ENV
    
    - name: Set up environment for local mode
      if: steps.check_databricks.outputs.databricks_available == 'false'
      run: |
        echo "MLFLOW_TRACKING_URI=sqlite:///mlflow.db" >> $GITHUB_ENV
    
    - name: Deploy to Production
      run: |
        python src/deploy_model.py --stage production
    
    - name: Notify deployment
      run: |
        echo "Model deployed to production successfully!"

